{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from pathlib import Path\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import wandb\n",
    "import numpy as np\n",
    "# from evaluate import evaluate\n",
    "# from unet import UNet\n",
    "# from utils.data_loading import BasicDataset, CarvanaDataset\n",
    "# from utils.dice_score import dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_img = Path('./data/carvana-image-masking-challenge/train_hq/')\n",
    "# dir_mask = Path('./data/carvana-image-masking-challenge/train_masks/')\n",
    "dir_img = Path(r'dataset\\detection\\JPEGImages'.replace('\\\\', '/'))\n",
    "dir_xml = Path(r'dataset\\detection\\Annotations'.replace('\\\\', '/'))\n",
    "dir_checkpoint = Path('./checkpoints/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import xml.etree.ElementTree as ET\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image  # 引入 PIL 庫\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def parse_xml_annotation(xml_file):\n",
    "    \"\"\"\n",
    "    解析 XML 標註文件，返回圖像文件名和 bounding box 資訊。\n",
    "    \n",
    "    :param xml_file: XML 文件的路徑\n",
    "    :return: 包含文件名和 bounding box 的字典 {'file': 'image_name.jpg', 'bboxes': [[xmin, ymin, xmax, ymax], ...]}\n",
    "    \"\"\"\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    filename = root.find('filename').text\n",
    "    bboxes = []\n",
    "    \n",
    "    for obj in root.findall('object'):\n",
    "        bndbox = obj.find('bndbox')\n",
    "        xmin = int(bndbox.find('xmin').text)\n",
    "        ymin = int(bndbox.find('ymin').text)\n",
    "        xmax = int(bndbox.find('xmax').text)\n",
    "        ymax = int(bndbox.find('ymax').text)\n",
    "        bboxes.append([xmin, ymin, xmax, ymax])\n",
    "    \n",
    "    return {'file': filename, 'bboxes': bboxes}\n",
    "\n",
    "class UNetDatasetWithBoundingBoxes(Dataset):\n",
    "    def __init__(self, img_dir: str, xml_dir: str, transform = None, img_scale: float = 1.0, mask_suffix: str = ''):\n",
    "        \"\"\"\n",
    "        :param img_dir: 圖片目錄的路徑\n",
    "        :param xml_dir: 標註 XML 文件的目錄\n",
    "        :param transform: 圖片轉換操作\n",
    "        :param img_scale: 圖片的目標大小 * scale\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.xml_dir = xml_dir\n",
    "        self.transform = transform\n",
    "        self.img_scale = img_scale\n",
    "        self.annotations = self.load_annotations()\n",
    "        self.mask_suffix = mask_suffix\n",
    "\n",
    "        return \n",
    "    \n",
    "    def load_annotations(self):\n",
    "        annotations = []\n",
    "        for xml_file in os.listdir(self.xml_dir):\n",
    "            if xml_file.endswith('.xml'):\n",
    "                annotation = parse_xml_annotation(os.path.join(self.xml_dir, xml_file))\n",
    "                annotations.append(annotation)\n",
    "        return annotations\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # get bounding box\n",
    "        annotation = self.annotations[index]\n",
    "        img_path = os.path.join(self.img_dir, annotation['file'])     \n",
    "        bboxes = annotation['bboxes']\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    # not necessary\n",
    "        mask = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n",
    "        \n",
    "                # 使用每個 bounding box 畫出矩形\n",
    "        for bbox in bboxes:\n",
    "            xmin, ymin, xmax, ymax = bbox\n",
    "            print(bbox)\n",
    "            cv2.rectangle(mask, (xmin, ymin), (xmax, ymax), color=1, thickness=-1) \n",
    "\n",
    "        # print((mask))\n",
    "        # plt.show(mask.any())   \n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        # 重新調整圖片和 mask 的大小\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return {\n",
    "            'image': img,\n",
    "            'mask': mask\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義轉換操作\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # 調整到所需大小\n",
    "    transforms.ToTensor()  # 轉換為 PyTorch 張量\n",
    "])\n",
    "\n",
    "# 設定圖片和 XML 標註文件的目錄\n",
    "image_dir = '/path/to/images'\n",
    "xml_dir = '/path/to/annotations'\n",
    "\n",
    "# 實例化數據集\n",
    "dataset = UNetDatasetWithBoundingBoxes(img_dir=image_dir, xml_dir=xml_dir, transform=transform)\n",
    "\n",
    "# 創建 DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# 示例：遍歷 DataLoader\n",
    "for batch in dataloader:\n",
    "    images, masks = batch['image'], batch['mask']\n",
    "    print(images.shape, masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200, 90, 216, 108]\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGgCAAAAADJXeyFAAADVklEQVR4Ae3RsQmAUBQEQbX/nrUAkwuERRjjh8efPQ4fAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIBAI3A2s9+vvh5yf79R/PEqRm3uAgLtVsmlQAn7PirQbpVcCpSw76MC7VbJpUAJ+z4q0G6VXAqUsO+jAu1WyaVACfs+KtBulVwKlLDvowLtVsmlQAn7PirQbpVcCpSw76MC7VYuCRAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQJ/EXgAiAoBJupkHaUAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=416x416>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = UNetDatasetWithBoundingBoxes(dir_img, dir_xml)\n",
    "dataset[10]['mask']\n",
    "# dataset[10]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# dataset[10]['image']\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[53], line 72\u001b[0m, in \u001b[0;36mUNetDatasetWithBoundingBoxes.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     70\u001b[0m     xmin, ymin, xmax, ymax \u001b[38;5;241m=\u001b[39m bbox\n\u001b[1;32m     71\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mrectangle(mask, (xmin, ymin), (xmax, ymax), color\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, thickness\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# 將 OpenCV 圖片轉換為 PIL 圖片以應用 transforms\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# img = transforms.ToPILImage()(img)\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# mask = transforms.ToPILImage()(mask)\u001b[39;00m\n\u001b[1;32m     76\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader\n",
    "1. transfer xml and image to data\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pathlib\n",
    "# import xml.etree.ElementTree as ET\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# ROOT_PATH = '/home/ddd/Desktop/D_codes/ML/dataset' # fill the dir where you place the dataset\n",
    "\n",
    "# def vis_label(image_name,purpose,fs=10):\n",
    "#     xml_path = pathlib.Path(ROOT_PATH,purpose,'Annotations',image_name).with_suffix('.xml')\n",
    "#     label = ET.parse(xml_path).getroot()\n",
    "#     xmin = int(label.find('object').find('bndbox').find('xmin').text)\n",
    "#     ymin = int(label.find('object').find('bndbox').find('ymin').text)\n",
    "#     xmax = int(label.find('object').find('bndbox').find('xmax').text)\n",
    "#     ymax = int(label.find('object').find('bndbox').find('ymax').text)\n",
    "\n",
    "#     image_path = pathlib.Path(ROOT_PATH,purpose,'JPEGImages',image_name).with_suffix('.jpg')\n",
    "#     # image = plt.imread(image_path)\n",
    "#     image = cv2.imread(image_path)\n",
    "\n",
    "#     cv2.rectangle(image,[xmin,ymin],[xmax,ymax],(255,0,0),1)\n",
    "\n",
    "#     plt.figure(figsize=(fs,fs))\n",
    "#     plt.imshow(image)\n",
    "#     plt.show()\n",
    "\n",
    "# wrong_label = []\n",
    "# rectangle_bbox = []\n",
    "\n",
    "# for purpose in ['detection','tracking']:\n",
    "#     root_path = pathlib.Path(ROOT_PATH,purpose,'Annotations')\n",
    "#     for xml_path in sorted(root_path.iterdir()):\n",
    "#         label = ET.parse(xml_path).getroot()\n",
    "#         H = int(label.find('size').find('height').text)\n",
    "#         W = int(label.find('size').find('width').text)\n",
    "\n",
    "#         xmin = float(label.find('object').find('bndbox').find('xmin').text)\n",
    "#         ymin = float(label.find('object').find('bndbox').find('ymin').text)\n",
    "#         xmax = float(label.find('object').find('bndbox').find('xmax').text)\n",
    "#         ymax = float(label.find('object').find('bndbox').find('ymax').text)\n",
    "\n",
    "#         if (xmin<0)|(ymin<0)|(xmax>=W)|(ymax>=H)|(xmin>xmax)|(ymin>ymax):\n",
    "#             wrong_label.append([xml_path,xmin,xmax,ymin,ymax,H,W])\n",
    "\n",
    "#         if not (1/2 < abs(xmax-xmin)/abs(ymax-ymin) < 2):\n",
    "#             rectangle_bbox.append([xml_path,xmin,xmax,ymin,ymax])\n",
    "\n",
    "# print(len(rectangle_bbox)) #count 105\n",
    "# print(len(wrong_label)) #count 5\n",
    "\n",
    "# for w in wrong_label:\n",
    "#     vis_label(w[0].with_suffix('').name,w[0].parent.parent.name)\n",
    "\n",
    "# for r in rectangle_bbox:\n",
    "#     vis_label(r[0].with_suffix('').name,r[0].parent.parent.name,5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "u_net_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
